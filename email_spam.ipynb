{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Spam Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all the pre-requisite dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# StratifiedFold is preferred for more uniform splitting\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold  \n",
    "from sklearn.metrics import confusion_matrix                          \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data\n",
    "The downloaded Spambase dataset (http://archive.ics.uci.edu/ml/datasets/Spambase) consists of 4,601 e-mails, of which `1,813 are spam` (39.4%). The data set archive contains a processed version of the e-mails wherein `57 real-valued features` have been extracted and the spam/non-spam label has been assigned.\n",
    "![one](images/one.png)\n",
    "![two](images/two.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching the data and generating the features set(x), target set(y)\n",
    "data = pd.read_csv('spambase.data').values\n",
    "x = data[:,:48]   # considering only WORD_frequency attribute (can use all of 57 features too)\n",
    "y = data[:,-1]    # the last column signifies spam(1) or not spam(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters regarding model tuning\n",
    "Given different sets of parameters pertaining to a machine learning model and/or data preprocessing algorithms, or even two or more different models, the goal of model tuning and/or model selection is to pick a set of parameters of a classifier so that the best averaged performance is achieved. With these concepts in mind, we tweak our naive Bayes classifier incorporating with cross-validation.\n",
    "> We choose to explore the following values for the parameter tuning:\n",
    "- __*alpha*__ : smoothing factor, the initial count for a term\n",
    "- __*fit_prior*__ : whether or not to use a prior tailored to the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing_factors = [0.5, 1.0, 1.5, 2.0]\n",
    "fit_prior = [True, False]\n",
    "# initialing parameters so as to retrieve the final dataframe with minimum error\n",
    "df_final = None   \n",
    "mean_final = None\n",
    "err_final = 1\n",
    "alpha_final = None\n",
    "prior_final = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the classification model\n",
    "The classification model built upon scikit-learn's `MultinomialNB` classifer. We initialize a model with smoothing factor (specified as `alpha` in scikit-learn) and prior learned from the training set (specified as `fit_prior` in scikit-learn). We simply cannot adopt the classification results from one fixed testing set, therefore, we usually apply the __*k-fold cross-validation*__ technique to assess how a model will generally perform in practice. Statistically, the averaged performance over __*k*__-fold cross-validation is an accurate estimate of how a model performs in general. Given different sets of parameters pertaining to a machine learning model and/or data preprocessing algorithms, or even two or more different models, the goal of model tuning and/or model selection is to pick a set of parameters of a classifier so that the best averaged performance is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function regarding classification model, returns error & confusion matrix \n",
    "# pertinent to a perticular fold\n",
    "def model_train(model,X_train, X_test, Y_train, Y_test):\n",
    "    model.fit(X_train,Y_train)                           # training the classifier\n",
    "    y_pred_class = model.predict(X_test)\n",
    "    cfn_mtrx = confusion_matrix(Y_test, y_pred_class)\n",
    "# calculating the error after testing the classifier\n",
    "    error = 1 - model.score(X_test,Y_test)  \n",
    "    return error,cfn_mtrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha  Fit_prior  Avg. Error\n",
      " 0.5     True       14.12%\n",
      " 0.5     False       14.86%\n",
      " 1.0     True       14.18%\n",
      " 1.0     False       14.88%\n",
      " 1.5     True       14.25%\n",
      " 1.5     False       14.97%\n",
      " 2.0     True       14.27%\n",
      " 2.0     False       15.03%\n",
      "\n",
      "Retrieved parameters for min. error of 14.12% ::: Alpha = 0.5 , Fit_prior = True\n"
     ]
    }
   ],
   "source": [
    "# performing k-fold cross validation for each set of parameters(alpha, fit_prior)\n",
    "print('Alpha  Fit_prior  Avg. Error')\n",
    "for i in smoothing_factors:\n",
    "    for j in fit_prior:\n",
    "        values = []\n",
    "        model = MultinomialNB(alpha=i, fit_prior=j)\n",
    "        folds = StratifiedKFold(n_splits = 10)                 # initializing a 10-fold generator\n",
    "        for train_index,test_index in folds.split(x,y):\n",
    "            X_train, X_test = x[train_index], x[test_index]\n",
    "            Y_train, Y_test = y[train_index], y[test_index]\n",
    "            error, cfn_mtrx = model_train(model,X_train, X_test, Y_train, Y_test)\n",
    "            values.append([error,cfn_mtrx[0][1],cfn_mtrx[1][1]])\n",
    "        df = pd.DataFrame(values, columns = ['Error','FP','FN'])\n",
    "        mean = df.mean(axis = 0)\n",
    "        print(' {}     {}       {:.2f}%'.format(i,j,mean[0]*100))\n",
    "# retrieving the set of parameters that give minimum error\n",
    "        if mean[0] < err_final:        \n",
    "            err_final = mean[0]\n",
    "            df_final = df\n",
    "            mean_final = mean\n",
    "            alpha_final = i\n",
    "            prior_final = j\n",
    "print('\\nRetrieved parameters for min. error of {:.2f}% ::: Alpha = {} , Fit_prior = {}'.format(err_final*100,alpha_final,prior_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the results\n",
    "In the following table, one row per fold shows corresponding false positive, false negative, and overall error rates, and add one final row corresponding to the average error rates across all folds. \n",
    "> For this problem: \n",
    "- __FP__ - *false positive* is the fraction of non-spam testing examples that are misclassified as spam(1) \n",
    "- __FN__ -  *false negative* is the fraction of spam testing examples that are misclassified as non-spam(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Error   FP   FN\n",
      "0  0.093275   32  171\n",
      "1  0.080260   29  174\n",
      "2  0.097826   35  171\n",
      "3  0.084783   37  179\n",
      "4  0.154348   60  170\n",
      "5  0.095652   40  177\n",
      "6  0.056522   20  175\n",
      "7  0.104348   35  168\n",
      "8  0.359477  153  169\n",
      "9  0.285403  104  154\n",
      "\n",
      "Avg. Error rate across all folds = 14.12%\n"
     ]
    }
   ],
   "source": [
    "# dataframe containing 10 generated folds regarding aforementioned minimum error\n",
    "print(df_final)         \n",
    "print('\\nAvg. Error rate across all folds = {:.2f}%'.format(mean_final[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting Classification error per fold\n",
    "x_pos = list(range(1,11))\n",
    "y_pos = list(df_final['Error'])\n",
    "index = np.arange(len(x_pos))\n",
    "plt.bar(index, y_pos)\n",
    "plt.xlabel('Value of Fold')\n",
    "plt.ylabel('Classification Error')\n",
    "plt.xticks(index, x_pos)\n",
    "plt.title('Classification Error per Fold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "From the above, we can observe the performance of a simple Naive Bayes classification model with an __accuracy of 86%.__ Moreover, in order to increase this accuracy we can select other classification algorithms (like Random Forest, Decision Trees etc.) or deal with selection of features giving optimum results. However, considering the simplicity and in order to avoid fitting problems Naive Bayes works nicely."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
